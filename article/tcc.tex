\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{fancyvrb}
\usepackage{caption}
\usepackage{subcaption}

\newcommand\slsh{\char`\\}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=cyan,
    filecolor=blue,      
    urlcolor=cyan,
    citecolor=cyan,
}
 
\sloppy

\title{Estudo relativo ao desempenho em função do consumo sobre alta demanda de dados em sistemas web desenvolvidos com \textit{Node.JS} e \textit{React.JS}}

\author{Marcos Renan Krul\inst{1}, Renato Cristiano Ruppel\inst{1}, Prof. Dr. Adriano Ferrsa\inst{1}}


\address{Universidade Estadual de Ponta Grossa (UEPG)
    \email{19022626@uepg.br, 19010426@uepg.br, ferrasa@uepg.br}
}


\begin{document} 

\maketitle


\begin{resumo} 
% especificar quantos gb/tb
\end{resumo}


\begin{abstract} 
\end{abstract}


\section{Introdução}

O desenvolvimento de novas aplicações e a migração das já existentes para a plataforma \textit{web} 
vêm crescendo e se tornando uma tendência \cite{SOUZAB}. Existem benefícios que justificam esse comportamento,
como facilidades em instalações e atualizações, alcance global instantâneo e alta portabilidade. Porém,
sob outra perspectiva, apresentam-se questões críticas que devem ser analisadas antes de aderir à plataforma, como
o desempenho em situações com alta demanda de dados.

O uso de \textit{Node.JS} e \textit{React.JS}, duas tecnologias em crescente uso e relevância no
desenvolvimento \textit{web}, justifica-se pelo fato de que estas permitem uma abordagem de alta
performance e apresentam recursos para otimização e escalabilidade. O \textit{Node.JS}, em específico, apresenta
bons resultados em casos que necessitem da persistência de centenas ou milhares de conexões
simultâneas, onde a comunicação é realizada com o envio de pequenos fragmentos do arquivo de destino
\cite[p. 112]{EJSMONT}. Quanto à camada \textit{front-end}, a biblioteca \textit{React.JS} traz como
carro chefe o gerenciamento de estado da aplicação, orientado a dados que podem mudar com o passar do tempo.
Ao incluir estado em uma aplicação utilizando \textit{React.JS}, inclui-se a possibilidade de criar, ler
e modificar dados dinâmicos enviados pelo servidor, que modificam a árvore de componentes e acarretam 
mudanças na interface em que o usuário interage \cite[p. 97]{BANKSEPORCELLO}.

Aplicações como colaboração de documentos e tarefas, jogos e \textit{streaming} de vídeo \cite{ZRHR} devem processar 
arquivos de grande porte, de forma rápida e estável. Contudo, existem limitações inerentes ao uso da 
plataforma \textit{web}, como o processamento de diversas requisições que exijam muitos dados, 
tratamento do alto fluxo de dados pela máquina cliente e os limites impostos pelas tecnologias escolhidas.

Para sobrepujar os problemas supracitados, existem técnicas desenvolvidas para a \textit{web} que buscam
atenuar os problemas de alta demanda e torná-los irrisórios na experiência do usuário, como o processamento
assíncrono (\textit{streams}) e \textit{caching}. Faz-se necessário, portanto, desenvolver um estudo das 
técnicas escolhidas para aumentar o desempenho em alta demanda de dados utilizando os \textit{frameworks} 
escolhidos.


\section{Revisão de bibliografia e trabalhos relacionados}

\subsection{Padrões de projeto no \textit{Node.JS}}

Padrões de projeto são soluções previamente definidas para problemas específicos que, geralmente,
são comuns ao desenvolvimento do \textit{software} de diversas aplicações. Não são, necessariamente, 
bibliotecas ou módulos prontos, apenas carregam o conceito de uma solução já comprovada e testada para um 
determinado caso, sendo, dessa forma, necessária a implementação destes na 
linguagem escolhida \cite[p. 13]{DIOGORESENDE}.

Um único \textit{software} pode ser implementado com diferentes padrões de projeto e, até mesmo, com a união
de dois ou mais. Os padrões apresentam diversos benefícios, como aumento da produtividade, manutenção e comunicação
entre a equipe de desenvolvimento. Contudo, a definição das soluções arquiteturais adotadas deve ser 
cuidadosa, visto que escolhas incorretas podem acarretar em novos empecilhos. Dentre outras, 
alguns \textit{designs} adicionam camadas extras de processamento para obter maior flexibilidade, podendo, dessa forma, 
afetar as métricas de desempenho do sistema final \cite[p. 13 - p. 14]{DIOGORESENDE}.

Dentre a maioria dos padrões de projeto conhecidos, existem aqueles que são amplamente utilizados no 
\textit{Node.JS}, devido à sua estrutura e ao seu modelo de interface. Dentre eles, evidenciam-se
os padrões de fluxo de eventos e os orientados a eventos, já presentes e fundamentados na interface principal 
da plataforma. É possível, por exemplo, substituir o modo de leitura de um arquivo de 
uma simples função somada à uma \textit{callback}, que irá consumir mais recursos de máquina, para um fluxo de 
leitura onde é possível verificar os eventos de dados e de conclusão, ou até mesmo encaminhar o fluxo para 
outra camada de processamento. Da mesma forma que ocorre com os arquivos, o controle dos eventos 
de conexão, recebimento de dados e encerramento está presente em módulos principais como, por exemplo, 
o \textit{http}. Em suma, eventos são recursos fundamentais do \textit{Node.JS} \cite[p. 15]{DIOGORESENDE}.


\subsection{Arquitetura orientada a eventos}

A arquitetura orientada a eventos (\textit{Event-Driven Architecture}, EDA) baseia-se na ideia de produção e consumo 
de eventos, sendo que o consumo pode ser feito por um ou mais ouvintes ao mesmo tempo. A implementação da parte consumidora 
deve garantir que haja uma reação ao acontecimento de eventos, ao invés de simplesmente tentar detectar 
mudanças nos dados recebidos \cite[p. 27]{DIOGORESENDE}.

Operações envolvendo \textit{sockets}, \textit{streams} e arquivos são, em grande parte, 
realizados de forma assíncrona em aplicações escritas na plataforma do \textit{Node.JS}, da forma que o processamento
dos ouvintes é executado diante de algum disparo de evento. \cite{MFO} Ao adotar este tipo de arquitetura em um projeto, 
a aplicação passa a ter o fluxo de informação controlado pelos disparos, o que, dependendo do caso, pode ser a melhor 
escolha de padrão. Contudo, ainda é preciso se atentar a alguns detalhes e desvantagens ao utilizar esta abordagem,
visto que diversos erros de programação podem ser observados como, por exemplo, eventos não tratados e ouvintes
registrados tarde demais \cite[p. 28]{DIOGORESENDE}.

Como o fluxo de dados da aplicação passa a ser dependente do acontecimento de certos eventos, é preciso ter cuidado 
extra no código para não permitir brechas que podem levar a um \textit{deadlock},
em outras palavras, uma trava que impossibilita o prosseguimento do fluxo imaginado para a aplicação. Um 
\textit{deadlock} pode ocorrer quando, por motivos de implementação incorreta, um evento alvo esperado pelo
consumidor não é acionado, fazendo com que este fique preso em um ponto exato, não podendo avançar nem regredir.
A segunda questão a ser observada, que também vale para outros tipos de padrões, é o tratamento de erros consistente
e robusto. Ao passo que o ponto anterior pode não ser fatal para a aplicação como um todo, ignorar erros, principalmente
os lançados por módulos principais, acarretará em paradas fatais da aplicação \cite[p. 28]{DIOGORESENDE}.

O modelo orientado a eventos implementado na plataforma do \textit{Node.JS} é composto por duas partes: 
\textit{loop thread} e \textit{worker pool} (também conhecida como \textit{threadpool}). A primeira, em específico, 
diz respeito à uma única \textit{thread} responsável por executar o código fornecido pelo usuário, além 
das próprias \textit{callbacks} definidas para as respostas dos disparos de eventos. Como todo o código principal 
é executado em uma única \textit{thread}, o \textit{Node.JS} transfere certas operações mais custosas à \textit{worker pool}, 
com o objetivo de não travar a \textit{thread} principal responsável por receber novas solicitações de 
clientes \cite{BUGS} \cite{ATOMICITY}, 
como, por exemplo, operações de I/O para as quais sistemas operacionais não oferecem uma versão não-bloqueante 
\cite{NODEBLOCKEVENTLOOP}. 

\begin{figure}[h]
\centering
\caption{Modelo da abordagem EDA no \textit{Node.JS}}
\includegraphics[width=0.8\textwidth]{images/pt-br/eda-arch-nodejs.png}
\label{fig:nodejs_eda_model}

Fonte: Adaptado de \cite{BUGS}.
\end{figure}

A \autoref{fig:nodejs_eda_model} apresenta o modelo utilizado na arquitetura orientada a eventos da plataforma do 
\textit{Node.JS}. No fluxo de processamento de eventos, a primeira etapa realizada pela \textit{loop thread} é 
a busca de um evento no \textit{event loop} e, caso sua \textit{callback} não possa ser executada na mesma, ocorre
a transferência para a \textit{worker pool}, registrando uma nova \textit{callback} associada. 
Na figura, é possível observar este comportamento nas etapas 1.1 e 1.2, onde as ações de criação e leitura de 
um arquivo são transferidas à \textit{worker pool}, visto que são operações custosas e bloqueantes. Dada 
a transferência, a \textit{thread} principal permanece não-bloqueada e pode continuar seu processamento. 
Dentro da \textit{worker pool}, novas \textit{threads} podem ser criadas para realizar a execução das operações
assíncronas de I/O e, ao término, os eventos serão inseridos na fila específica para I/O (\textit{Node.JS} 
possui sete filas de eventos para diferentes tipos, sendo eles: temporizador, I/O, pendente, ocioso, preparação, 
verificação e fechamento \cite{NODEEVENTLOOP}). Na figura, as etapas 2.1 e 2.2 representam este comportamento.
Por fim, a \textit{loop thread} busca estes novos eventos na fila e executa suas 
\textit{callbacks} (etapas 3.1 e 3.2) \cite{BUGS}.


\subsection{EDA \textit{vs.} OPTC}

A abordagem EDA, descrita na seção anterior, realiza multiplexação de uma única \textit{thread} para processar 
as requisições dos clientes, reduzindo, dessa forma, o consumo de recursos de máquina. 
A arquitetura de \textit{multithreading}, abordagem tradicional de aplicações \textit{web}, por sua vez, baseia-se
no conceito de uma \textit{thread} por cliente (\textit{One Thread Per Client}, OTPC), ou seja, cada requisição
recebida pelo servidor é atribuida à uma nova \textit{thread} para processamento isolado dos clientes, reduzindo
problemas relacionados à interferências. Contudo, cada requisição recebida resulta em sobrecarga no uso de
recursos de máquina e em trocas de contexto \cite{JGD}. Dessa forma, os custos computacionais aumentam
à medida que novos clientes realizam suas requisições, fazendo com que os sitemas limitem o número máximo de
\textit{threads} e, consequentemente, travem a escalabilidade do servidor \cite{ZRHR}.


\subsection{\textit{Stream}}

As \textit{streams} representam uma das mais importantes estruturas na plataforma do \textit{Node.JS}, por motivos
como aumento em desempenho e eficiência, possibilidade de criação de códigos elegantes e pela sua compatibilidade
no modelo da arquitetura orientada a eventos do \textit{Node.JS} \cite[p. 119]{MARIO}. Oferecem uma interface facilitada 
e rápida para leitura, gravação e transformação, da forma que é possível encadear dados entre estas operações 
para processá-los e, se necessário, transformá-los. Além dessas, essa estrutura está relacionada com os eventos, visto que
utilizam destes para enviar notificações aos consumidores quando os dados estão prontos para consumo ou quando o
processamento chegou ao fim \cite[p. 28]{DIOGORESENDE}.

O modelo da arquitetura baseada em eventos do \textit{Node.JS} aumenta o poder das \textit{streams}, visto que,
em plataformas baseadas em eventos, a maneira mais eficiente para tratamento de I/O é com processamento em tempo real.
Dessa forma, a aplicação irá consumir os dados de entrada a medida que estes estão disponíveis, e o envio dos dados
de saída será de acordo com o rítimo de produção da aplicação \cite[p. 119]{MARIO}.

As \textit{streams}, além desta, são utilizadas em problemas que não apresentam soluções tecnicamente
possíveis com outras interfaces presentes na plataforma do \textit{Node.JS}, como, por exemplo, a leitura de 
arquivos suficientemente grandes com funções que retornam um \textit{buffer} ao término da leitura completa. Arquivos com 
centenas de \textit{megabytes} ou até mesmo \textit{gigabytes}, precisariam ser carregados em um único 
\textit{buffer}, o que torna esse cenário inviável, visto que a aplicação ficaria sem memória, ainda mais ao 
imaginarmos cenários de aplicações  \textit{web} onde seria necessário realizar diversas leituras simultâneas.
Além destas, o V8 (mecanismo presente no \textit{Node.JS} responsável pela execução de códigos \textit{JavaScript} \cite{NODEV8}) impõe 
um limite máximo de, aproximadamente, 1 GB para \textit{buffers}, o que explica a impossibilidade técnica para problemas 
desta natureza \cite[p. 122]{MARIO}.

\subsection{\textit{Buffer}}

Os \textit{buffers}, no \textit{Node.JS}, são objetos especiais utilizados para armazenamento e processamento 
de dados binários, o que não seria possível operando com tipos primitivos do \textit{JavaScript} como, por exemplo,
\textit{strings}, visto que estas são codificadas em \textit{Unicode} \cite[p. 29]{DIOGORESENDE}.

Além da possibilidade de manipulação de dados binários e da facilidade em leituras e escritas de números de diferentes 
tamanhos, os \textit{buffers} são uma importante estrutura na plataforma do \textit{Node.JS} em relação à arquitetura
orientada a eventos, dada a compatibilidade binária existente entre os principais módulos da plataforma que 
utilizam estes nos eventos de dados. Dessa forma, é possível que arquivos sejam transmitidos ao cliente de maneira 
simplificada, ao modo que esta operação se resume ao encadeamento de \textit{streams} com a troca de 
\textit{buffers} entre cliente e servidor \cite[p. 29]{DIOGORESENDE}.


\section{Metodologia}


Nesta seção será descrita a metodologia proposta para a pesquisa do tema, esta que tem caráter semi-experimental, qualitativo
e escopo exploratório. Sendo o objetivo desta pesquisa investigar o impacto do consumo de recursos no desempenho de sistemas
web baseados em Node.JS quando confrontados com uma demanda intensa de dados.

4.?. Planejamento Experimental

O estudo será realizado em um ambiente controlado, onde serão desenvolvidos cenários de teste representativos de diferentes 
níveis de consumo de dados. Serão definidos parâmetros, como tamanhos de dados a serem transferidos e cargas 
de trabalho, para simular situações de baixa, média e alta demanda de dados.

4.?. Construção do Ambiente de Teste

Será configurado um ambiente de teste composto por uma aplicação servidor e uma aplicação cliente. . 
O servidor de aplicação será baseado em Node.JS, utilizando a versão xx.xx.xx. 
A aplicação cliente terá uma interface básica construída apenas com HTML5.

% 4.3. Definição dos Cenários de Teste

% Serão definidos três cenários de teste para avaliar o desempenho do sistema em diferentes níveis de consumo de dados. Cada cenário 
% representará uma carga de trabalho específica, com diferentes quantidades de requisições simultâneas e tamanhos de dados a serem 
% processados. Os cenários de teste serão nomeados da seguinte forma:

% Cenário 1: Baixa demanda de dados - 100 requisições simultâneas com uma carga de dados pequena (100KB).
% Cenário 2: Média demanda de dados - 500 requisições simultâneas com uma carga de dados moderada (1MB).
% Cenário 3: Alta demanda de dados - 1000 requisições simultâneas com uma carga de dados grande (10MB).
% 4.4. Coleta de Dados

% Serão definidos indicadores de desempenho a serem coletados durante a execução dos cenários de teste. Os principais indicadores 
% incluirão o tempo de resposta das requisições, a taxa de transferência, a utilização de CPU e memória, e a latência do banco de dados. 
% Serão utilizadas ferramentas de coleta de dados adequadas, como o Apache JMeter e o MongoDB Profiler, para garantir a precisão 
% e consistência dos resultados.

% 4.5. Análise de Dados

% Os dados coletados serão analisados estatisticamente para identificar padrões, tendências e relações entre o consumo de dados e 
% o desempenho do sistema. Serão utilizadas técnicas de análise descritiva e inferencial para interpretar os resultados e obter 
% insights significativos. Serão realizadas comparações entre os cenários de teste para identificar diferenças significativas 
% em termos de desempenho.

% 4.6. Considerações Éticas

% Serão adotadas medidas para garantir a ética na condução da pesquisa. Será assegurada a anonimização dos dados coletados e 
% a conformidade com as diretrizes de ética em pesquisa. Além disso, serão respeitadas as normas de privacidade e proteção 
% de dados, e o ambiente de teste será isolado para evitar qualquer impacto negativo em sistemas em produção.

\subsection{Revisão sistemática da literatura}

% 1. Revisão bibliográfica de documentação e artigos referentes à
% linguagem e frameworks escolhidos para o tratamento de alta
% demanda de dados.
% 2. Análise de casos e implementações feitas pela comunidade
% desenvolvedora de software.
% 3. Comparação de diferentes implementações feitas em sistemas web
% para a manipulação e transferência de alto volume de dados.
% 4. Desenvolvimento de aplicações cliente e servidor para transferência de
% alto volume de dados.

\section{Resultados e discussão}


\section{Conclusão}


\bibliographystyle{sbc}
\bibliography{referencias}

\end{document}