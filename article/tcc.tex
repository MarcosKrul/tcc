\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{fancyvrb}
\usepackage{caption}
\usepackage{enumerate}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{color}
\renewcommand\lstlistingname{Código}
\def\lstlistingautorefname{Código}

\newcommand\slsh{\char`\\}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=cyan,
    filecolor=blue,      
    urlcolor=cyan,
    citecolor=cyan,
}
 
\sloppy

\title{Estudo relativo ao desempenho em função do consumo sobre alta demanda de dados em sistemas web desenvolvidos com \textit{Node.JS}}

\author{Marcos Renan Krul\inst{1}, Renato Cristiano Ruppel\inst{1}, Prof. Dr. Adriano Ferrasa\inst{1}}


\address{Universidade Estadual de Ponta Grossa (UEPG)
    \email{19022626@uepg.br, 19010426@uepg.br, ferrasa@uepg.br}
}

\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}

\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
	language=JavaScript, 
	basicstyle=\small\ttfamily, 
	breaklines=true, 
	numbers=left, 
	numberstyle=\tiny\color{lightgray}, 
	stepnumber=1, 
	numbersep=8pt, 
	frame=single, 
	showspaces=false,
	showstringspaces=false,
	showtabs=false,
	captionpos=b, 
	xleftmargin=15pt, 
	xrightmargin=0pt, 
	tabsize=2, 
	commentstyle=\color{green!40!black}, 
	keywordstyle=\color{blue}, 
	stringstyle=\color{red}
}


\begin{document} 

\maketitle


\begin{resumo} 
O trabalho realiza um estudo sobre técnicas presentes na plataforma do \textit{Node.JS} para desenvolvimento de servidores \textit{web} 
que exijam processamento de grandes volumes de dados. Dentre os principais padrões de projeto, destaca-se a arquitetura orientada a eventos,
fortemente enraizada nos principais núcleos da plataforma, que, juntamente com as \textit{streams}, possibilita a leitura de arquivos 
com tamanho na ordem de \textit{gigabytes}. Serão criadas aplicações servidoras com o objetivo de testar a capacidade de lidar com altas 
demandas em aplicações web. Além disso, será avaliado como os recursos do servidor são utilizados ao lidar com a leitura e processamento 
de um arquivo de 1,65 GB. O resultado esperado é demonstrar que a arquitetura orientada a eventos é a solução mais eficaz para o 
desenvolvimento de aplicações web que lidam com grandes volumes de dados na plataforma Node.JS.
\end{resumo}


\begin{abstract} 
The work carries out a study of techniques present in the Node.JS platform for developing web servers that require processing large
volumes of data. Among the main design patterns, the event-driven architecture stands out, deeply rooted in the core of the platform, 
which, along with streams, enables the reading of files with sizes in the gigabytes range. Server applications will be created with the 
goal of testing the ability to handle high demands in web applications. Additionally, an evaluation will be conducted on how server 
resources are utilized when dealing with the reading and processing of a 1.65 GB file. The expected outcome is to demonstrate that the 
event-driven architecture is the most effective solution for developing web applications that deal with large volumes of data on the Node.JS platform.
\end{abstract}


\section{Introdução}

O desenvolvimento de aplicações \textit{web} bem como a migração de aplicações existentes para este ambiente,
é a realidade atual encontrada no mercado de \textit{software}. É considerado o meio mais utilizado
para comunicação e troca de informações atualmente, com mais de 2,5 quintilhões de \textit{bytes} de dados
carregados por diferentes serviços ofertados. Dentre outras, até janeiro de 2020, foram 
contabilizados cerca de 4,45 bilhões de usuários de \textit{internet} \cite{WEBUSAGE}. 
Existem benefícios que justificam esse comportamento, como facilidades em instalações e atualizações, 
alcance global instantâneo e alta portabilidade. Porém, sob outra perspectiva, apresentam-se questões 
críticas que devem ser analisadas antes de aderir à plataforma, como o desempenho em situações com 
alta demanda de dados.

O uso de \textit{Node.JS}, tecnologia em crescente uso e relevância no
desenvolvimento \textit{web}, justifica-se pelo fato de que esta permite uma abordagem de alta
performance e apresenta recursos para otimização e escalabilidade. Essa plataforma apresenta
bons resultados em casos que necessitem da persistência de centenas ou milhares de conexões
simultâneas, onde a comunicação é realizada com o envio de pequenos fragmentos do arquivo ao destino
\cite[p. 112]{EJSMONT}.

Aplicações como colaboração de documentos e tarefas, jogos e \textit{streaming} de vídeo, áudio e imagens
\cite{ZRHR} devem processar arquivos com tamanhos na ordem de \textit{gigabytes}. 
Contudo, existem limitações inerentes ao uso da plataforma \textit{web}, como o processamento de 
diversas requisições que exijam esses arquivos, tratamento de dados pela máquina 
cliente e os limites impostos pelas tecnologias escolhidas.

Para sobrepujar os problemas supracitados, existem técnicas desenvolvidas para a \textit{web} que buscam
atenuar os problemas de alta demanda e torná-los irrisórios na experiência do usuário, como o processamento
assíncrono (\textit{streams}) e \textit{caching}. Faz-se necessário, portanto, desenvolver um estudo das 
técnicas escolhidas para aumentar o desempenho em alta demanda de dados utilizando a plataforma do \textit{Node.JS}.


\section{Revisão de bibliografia}

\subsection{Escalabilidade}

O termo escalabilidade pode ser definido como a maneira de ajustar a
capacidade de um sistema para atender demandas, de forma que o custo desta
operação não seja tão elevado. \cite[p. 3]{EJSMONT}. O \textit{Node.js}, devido à sua natureza
assíncrona, entrada e saída não bloqueantes e orientadas a eventos, caracteriza-se como
uma plataforma escalável. \cite[p. 2]{SCALABILITY}. A incorporação de escalabilidade
em um sistema pode compreender a capacidade de lidar com um crescimento de usuários, solicitações
e transações, para este projeto, seu uso será voltado para a requisição e transferência de grandes volumes de dados.


\subsection{Padrões de projeto no \textit{Node.JS}}

Padrões de projeto são soluções previamente definidas para problemas específicos que, geralmente,
são comuns ao desenvolvimento do \textit{software} de diversas aplicações. Não são, necessariamente, 
bibliotecas ou módulos prontos, apenas apresentam o conceito de uma solução já comprovada e testada para um 
determinado caso, sendo, dessa forma, necessária a implementação destes na 
linguagem escolhida \cite[p. 13]{DIOGORESENDE}.

Um único \textit{software} pode ser implementado com diferentes padrões de projeto e, até mesmo, com a união
de dois ou mais. Os padrões apresentam diversos benefícios, como aumento da produtividade, manutenção e comunicação
entre a equipe de desenvolvimento. Contudo, a definição das soluções arquiteturais adotadas deve ser 
cuidadosa, visto que escolhas incorretas podem acarretar em novos empecilhos como, por exemplo, a adição de
camadas extras de processamento para obter maior flexibilidade, podendo, dessa forma, 
afetar as métricas de desempenho do sistema final, como o tempo de execução \cite[p. 13 - p. 14]{DIOGORESENDE}.

Dentre a maioria dos padrões de projeto conhecidos, existem aqueles que são amplamente utilizados no 
\textit{Node.JS}, devido à sua estrutura e ao seu modelo de interface. Dentre eles, evidenciam-se
os padrões orientados a eventos, já presentes e fundamentados na interface principal 
da plataforma. É possível, por exemplo, substituir o modo de leitura de um arquivo de 
uma simples função somada à uma \textit{callback}, que irá consumir mais recursos de máquina, como memória \textit{RAM}, 
para um fluxo de leitura onde é possível verificar os eventos de dados e de conclusão, 
ou até mesmo encaminhar o fluxo para outra camada de processamento. Da mesma forma que ocorre com os 
arquivos, o controle dos eventos 
de conexão, recebimento de dados e encerramento está presente em módulos principais como, por exemplo, 
o \textit{http}. Observa-se que a arquitetura do \textit{Node.JS} baseia-se em eventos, sendo estes,
recursos fundamentais desta plataforma \cite[p. 15]{DIOGORESENDE}.


\subsection{Arquitetura orientada a eventos}

A arquitetura orientada a eventos (\textit{Event-Driven Architecture}, EDA) baseia-se na ideia de produção e consumo 
de eventos, sendo que o consumo pode ser feito por um ou mais ouvintes ao mesmo tempo. A implementação da parte consumidora 
deve garantir que haja uma reação ao acontecimento de eventos, ao invés de simplesmente tentar detectar 
mudanças nos dados recebidos \cite[p. 27]{DIOGORESENDE}.

Os sistemas operacionais oferecem operações bloqueantes para leitura e gravação em arquivos, fazendo com que ocorra
um bloqueio na execução do programa principal até que haja uma resposta das solicitações. Nesse contexto, até pequenos
bloqueio podem resultar no travamento de aplicações baseadas no modelo cliente/servidor e, dessa forma, novas requisições
deverão esperar. Para tal problema, operações de I/O não bloqueantes - também conhecidos como I/O assíncrono - oferecem
uma solução elegante, com o uso de \textit{callbacks} que serão invocadas ao fim das solicitações 
de leitura e escrita em arquivos \cite{UDESC}.

Operações envolvendo \textit{sockets}, \textit{streams} e arquivos são, em grande parte, 
realizados de forma assíncrona em aplicações escritas na plataforma do \textit{Node.JS}, da forma que o processamento
dos ouvintes é executado diante de algum disparo de evento. \cite{MFO} Ao adotar este tipo de arquitetura em um projeto, 
a aplicação passa a ter o fluxo de informação controlado pelo envio de eventos, o que, dependendo do caso, pode ser a melhor 
escolha de padrão. Contudo, ainda é preciso se atentar a alguns detalhes e desvantagens ao utilizar esta abordagem,
visto que diversos erros de programação podem ser observados como, por exemplo, eventos não tratados e ouvintes
registrados fora do tempo de interação \cite[p. 28]{DIOGORESENDE}.

Como o fluxo de dados da aplicação passa a ser dependente do acontecimento de certos eventos, é preciso ter cuidado 
extra no código para não permitir brechas que podem levar a um \textit{deadlock},
em outras palavras, uma trava que impossibilita o prosseguimento do fluxo imaginado para a aplicação. Um 
\textit{deadlock} pode ocorrer quando, por motivos de implementação incorreta, um evento alvo esperado pelo
consumidor não é acionado, fazendo com que este fique preso em um ponto exato, não podendo avançar nem regredir.
A segunda questão a ser observada, que também vale para outros tipos de padrões, é o tratamento de erros consistente
e robusto. Ao passo que o ponto anterior pode não ser fatal para a aplicação como um todo, ignorar erros, principalmente
os lançados por módulos principais, acarretará em paradas fatais da aplicação \cite[p. 28]{DIOGORESENDE}.

O modelo orientado a eventos implementado na plataforma do \textit{Node.JS} é composto por duas partes: 
\textit{loop thread} e \textit{worker pool} (também conhecida como \textit{threadpool}). A primeira, em específico, 
diz respeito à uma única \textit{thread} responsável por executar o código fornecido pelo usuário, além 
das próprias \textit{callbacks} definidas para as respostas dos disparos de eventos. Como todo o código principal 
é executado em uma única \textit{thread}, o \textit{Node.JS} transfere certas operações mais custosas à \textit{worker pool}, 
com o objetivo de não travar a \textit{thread} principal responsável por receber novas solicitações de 
clientes \cite{BUGS} \cite{ATOMICITY}, 
como, por exemplo, operações de I/O para as quais sistemas operacionais não oferecem uma versão não-bloqueante 
\cite{NODEBLOCKEVENTLOOP}. 

\begin{figure}[h]
\centering
\caption{Modelo da abordagem EDA no \textit{Node.JS}}
\includegraphics[width=0.8\textwidth]{images/pt-br/eda-arch-nodejs.png}
\label{fig:nodejs_eda_model}

Fonte: Adaptado de \cite{BUGS}.
\end{figure}

Na arquitetura orientada a eventos da plataforma do \textit{Node.JS} (\autoref{fig:nodejs_eda_model}), 
o fluxo de processamento de eventos da primeira etapa é realizada pelo \textit{loop thread}, 
buscando um evento no \textit{event loop} e, caso sua \textit{callback} não possa ser executada na mesma, ocorre
a transferência para a \textit{worker pool}, registrando uma nova \textit{callback} associada. 
Ainda, é possível observar este comportamento nas etapas 1.1 e 1.2, onde as ações de criação e leitura de 
um arquivo são transferidas à \textit{worker pool}, visto que são operações custosas e bloqueantes. Dada 
a transferência, a \textit{thread} principal permanece não-bloqueada e pode continuar seu processamento. 
Dentro da \textit{worker pool}, novas \textit{threads} podem ser criadas para realizar a execução das operações
assíncronas de I/O e, ao término, os eventos serão inseridos na fila específica para I/O (\textit{Node.JS} 
possui sete filas de eventos para diferentes tipos, sendo eles: temporizador, I/O, pendente, ocioso, preparação, 
verificação e fechamento \cite{NODEEVENTLOOP}). As etapas 2.1 e 2.2 representam este comportamento.
Por fim, a \textit{loop thread} busca estes novos eventos na fila e executa suas 
\textit{callbacks} (etapas 3.1 e 3.2) \cite{BUGS}.


\subsection{EDA \textit{vs.} OTPC}

A abordagem EDA, descrita na seção anterior, realiza multiplexação de uma única \textit{thread} para processar 
as requisições dos clientes, reduzindo, dessa forma, o consumo de recursos de máquina. 
A arquitetura de \textit{multithreading}, abordagem tradicional de aplicações \textit{web}, por sua vez, baseia-se
no conceito de uma \textit{thread} por cliente (\textit{One Thread Per Client}, OTPC), ou seja, cada requisição
recebida pelo servidor é atribuida à uma nova \textit{thread} para processamento isolado dos clientes, reduzindo
problemas relacionados à interferências. Contudo, cada requisição recebida resulta em sobrecarga no uso de
recursos de máquina e em trocas de contexto \cite{JGD}. Dessa forma, os custos computacionais aumentam
à medida que novos clientes realizam suas requisições, fazendo com que os sistemas limitem o número máximo de
\textit{threads} e, consequentemente, bloqueiem a escalabilidade do servidor \cite{ZRHR}.


\subsection{\textit{Stream}}

As \textit{streams} representam uma das mais importantes estruturas na plataforma do \textit{Node.JS}, por motivos
como aumento em desempenho e eficiência, possibilidade de criação de códigos elegantes e pela sua compatibilidade
no modelo da arquitetura orientada a eventos do \textit{Node.JS} \cite[p. 119]{MARIO}. Oferecem uma interface facilitada 
para leitura, gravação e transformação de dados, de forma que é possível realizar encadeamento 
entre estas operações para processá-los e, se necessário, transformá-los. Além dessas, essa estrutura está 
relacionada com os eventos, visto que utilizam destes para enviar notificações aos consumidores 
quando os dados estão prontos para consumo ou quando o processamento chegou ao fim \cite[p. 28]{DIOGORESENDE}.

O modelo da arquitetura baseada em eventos do \textit{Node.JS} aumenta a eficácia no uso das \textit{streams}, visto que,
em plataformas baseadas em eventos, a maneira mais eficiente para tratamento de I/O é com processamento em tempo real.
Dessa forma, a aplicação irá consumir os dados de entrada a medida que estes estão disponíveis, e o envio dos dados
de saída será de acordo com o ritmo de produção da aplicação \cite[p. 119]{MARIO}.

As \textit{streams}, além das características apresentadas, são utilizadas em problemas que não apresentam soluções tecnicamente
possíveis com outras interfaces presentes na plataforma do \textit{Node.JS}, como, por exemplo, a leitura de 
arquivos suficientemente grandes com funções que retornam um \textit{buffer} ao término da leitura completa. Arquivos com 
centenas de \textit{megabytes} ou até mesmo \textit{gigabytes}, precisariam ser carregados em um único 
\textit{buffer}, o que torna esse cenário inviável, visto que a aplicação ficaria sem memória, ainda mais ao 
imaginarmos cenários de aplicações \textit{web} onde seria necessário realizar diversas leituras simultâneas.
Ademais, o V8 (mecanismo presente no \textit{Node.JS} responsável pela execução de códigos \textit{JavaScript} \cite{NODEV8}) impõe 
um limite máximo de, aproximadamente, 1 GB para \textit{buffers}, o que explica a impossibilidade técnica para problemas 
desta natureza \cite[p. 122]{MARIO}.

\subsection{\textit{Buffer}}

Os \textit{buffers}, no \textit{Node.JS}, são objetos especiais utilizados para armazenamento e processamento 
de dados binários, o que não seria possível operando com tipos primitivos do \textit{JavaScript} como, por exemplo,
\textit{strings}, visto que estas são codificadas em \textit{Unicode} \cite[p. 29]{DIOGORESENDE}.

Além da possibilidade de manipulação de dados binários e da facilidade em leituras e escritas de números representados
com estruturas de tamanhos e formatos (\textit{big-endian} e \textit{little-endian}) diferentes, os \textit{buffers} são uma importante estrutura na plataforma do \textit{Node.JS} em relação à arquitetura
orientada a eventos, dada a compatibilidade binária existente entre os principais módulos da plataforma que 
utilizam estes nos eventos de dados. Dessa forma, é possível que arquivos sejam transmitidos ao cliente de maneira 
simplificada, ao modo que esta operação se resume ao encadeamento de \textit{streams} com a troca de 
\textit{buffers} entre cliente e servidor \cite[p. 29]{DIOGORESENDE}.


\subsection{\textit{Cluster}}

A técnica de clusterização pode ser utilizada para escalar horizontalmente um servidor em uma única máquina,
criando processos filhos, chamados de \textit{workers}, que executam de forma concorrente e compartilham uma mesma porta.
O \textit{Node.js} fornece o módulo de \textit{cluster} para permitir a execução de várias instâncias de aplicações na
mesma máquina. Esse módulo é semelhante ao módulo \textit{child\textunderscore process}, também nativo do \textit{Node.js},
que fornece o método \textit{fork} para criar subprocessos, sendo a principal diferença entre os dois módulos
um mecanismo adicional que permite o roteamento de solicitações recebidas, distribuindo-as entre as instâncias
criadas \cite[p. 76]{DISTRIBUTEDNODE}.

\section{Trabalhos relacionados}

Nesta seção, serão discutidos trabalhos relacionados que abordaram o desempenho e o consumo de recursos 
em sistemas \textit{web}, particularmente aqueles desenvolvidos com \textit{Node.js}. Esses estudos ajudam a contextualizar 
o presente trabalho e fornecem insights valiosos sobre otimizações e estratégias para lidar com demandas 
intensas de dados.

Um estudo anterior \cite{CLUSTERTCC} se concentrou na melhoria do desempenho em sistemas \textit{web} por meio de atualizações 
de código e da implementação do módulo de \textit{cluster} no ambiente \textit{Node.js}. Os resultados indicaram melhorias 
significativas, demonstrando a eficácia de distribuir a carga de trabalho entre processos paralelos usando a 
técnica de \textit{clustering}. Essa abordagem se alinha diretamente com o nosso objetivo de entender como o consumo 
de recursos afeta o desempenho em sistemas \textit{web} com \textit{Node.js}, especialmente sob alta demanda de dados.
Da mesma forma, \cite{CLUSTERTCC} explorou otimizações em funções de cálculo de custos em sistemas 
semelhantes. Observou-se que melhorias substanciais foram alcançadas ao aprimorar a eficiência na 
iteração de matrizes e no gerenciamento de memória. Esses resultados ressaltam a importância de abordar o 
processamento intensivo de dados para melhorar o desempenho geral do sistema, uma consideração crucial em 
nossa investigação sobre sistemas \textit{web} de alta demanda.

Além das melhorias já exploradas, o trabalho também apontou oportunidades não 
investigadas, como a compilação AOT (\textit{Ahead of Time}) e a implementação de processos dedicados em segundo 
plano. Essas estratégias oferecem caminhos adicionais para otimização e merecem consideração em futuras 
iterações do projeto. Além disso, a implantação segura de técnicas como o clustering foi destacada como uma 
consideração crítica, enfatizando a necessidade de garantir a estabilidade e a segurança do sistema em produção.

Outro estudo anterior por \cite{NODEJVERSUSIIS} realizou uma comparação e avaliação do desempenho entre \textit{Node.js}, a mais recente 
tecnologia, e o servidor \textit{IIS}, por meio de testes objetivos e sistemáticos. Os resultados 
destacaram que o \textit{Node.js} apresenta um bom desempenho em relação ao servidor tradicional \textit{IIS} na 
execução de tarefas intensivas de I/O. Além disso, o estudo sugeriu que o \textit{Node.js} é preferencialmente utilizado 
em situações de I/O intensivo, em vez de serviços intensivos em CPU. Ao observar os resultados de desempenho em 
termos de \textit{throughput}, o \textit{Node.js} emergiu como uma tecnologia amplamente adotada por muitas organizações, 
especialmente devido às suas vantagens em cenários de I/O intensivo.

Esses estudos não apenas contribuem para o entendimento do contexto em que o presente trabalho se insere, 
mas também fornecem um ponto de partida sólido para nosso próprio estudo sobre o desempenho em função 
do consumo de recursos em sistemas \textit{web} desenvolvidos com \textit{Node.js}. Ao avaliar suas metodologias e 
resultados à luz de nossos objetivos, podemos identificar lacunas e direções promissoras para nossa 
pesquisa, ampliando assim o conhecimento sobre estratégias de otimização e gerenciamento de recursos 
em ambientes de alta demanda.


\section{Metodologia}


% MÉTRICAS A SEREM ANALISADAS: 
%     - Consumo de memóra RAM
%     - Uso de CPU?
%   - Throughput??
%   - Latência do event loop
%   - Estatísticas de memória do Garbage Collector


A metodologia aplicada apresenta caráter semi-experimental, qualitativo
e escopo exploratório, para análise do desempenho de sistemas \textit{web} baseados em \textit{Node.JS} 
quando será gerada uma condição de tráfego de fluxo intenso de dados,
com tamanhos de arquivo na ordem de \textit{gigabytes}.

O estudo será realizado em um ambiente controlado, onde serão desenvolvidos cenários de teste com diferentes 
implementações de arquitetura para a resolução do problema de envio de dados, a fim de aferir métricas de desempenho do servidor, 
como o consumo de memória \textit{RAM}, \textit{throughput} (quantidade de requisições processadas por unidade 
de tempo - vazão). Uma implementação utilizará uma arquitetura não escalável e não 
pensada para o caso específico de transferência de um grande volume de dados, e outra aplicará técnicas focadas na 
manipulação de maiores volumes de dados.


\subsection{Implementações}

Serão abordadas, nesta seção, as implementações cruciais que foram desenvolvidas e 
otimizadas para avaliar e aprimorar o desempenho no ambiente \textit{Node.js}. Compreendendo a 
importância de alcançar um desempenho eficiente em aplicações \textit{web} com consumo de dados na ordem
de \textit{gigabytes}, foram adotadas estratégias e técnicas para maximizar a capacidade de 
processamento, minimizar os gargalos de execução e otimizar o consumo de recursos. 

\begin{lstlisting}[caption={Código base para um servidor \textit{Node.JS}}, label=cod:base]
	createServer(async (request, response) => {
		if (request.method === "OPTIONS") {
			response.writeHead(204, headers);
			response.end();
			return;
		}

		request.once("close", () => {
			console.log(`Connection was closed`);
			abortController.abort();
		});

		response.writeHead(200, headers);

		try {
			const { size } = await stat(filename);
			console.log("processing:", byteSize(size));

			{ ... }
		} catch (error) {
			console.error(`Error at server: ${error.message}`);
			response.statusCode = 500;
			response.end("Internal Server Error");
		}
	})
  .listen(PORT)
  .on("listening", () => console.log(`server is running at ${PORT}`));
\end{lstlisting}

O Código~\ref{cod:base} apresenta a estrutura base para criação de servidores simples usando a 
plataforma do \textit{Node.JS}. Para tal, é utilizada a função \textit{createServer} do módulo nativo \textit{http}.
A sua \textit{callback} recebe os objetos de requisição e resposta para tratamentos como definição de cabeçalhos, leitura
de valores de entrada e escrita de valores de saída. Dessa forma, o servidor para este estudo irá responder à chamadas
realizadas no caminho raíz da aplicação, em determinada porta arbitrária.

A primeira implementação realizada, ilustrada no Código~\ref{cod:sync}, realiza a leitura do arquivo de 1.65 GB
de forma síncrona utilizando chamadas do módulo \textit{fs} (\textit{file system}), ou seja, todo o conteúdo será
inserido dentro de um único \textit{buffer} e retornado assim que a operação esteja concluída. Este trecho de código
deve ser inserido dentro do servidor previamente implementado no Código~\ref{cod:base}.

\begin{lstlisting}[caption={Implementação da leitura do arquivo de forma síncrona}, label=cod:sync]
	const data = fs.readFileSync(filename);
	response.end(data);
\end{lstlisting}

O Código~\ref{cod:async} apresenta a implementação inicial para a leitura do arquivo de 1.65 GB de forma assíncrona,
onde o conteúdo será processado sob demanada em pequenas porções - denominadas \textit{chunks}. Para tal, é utilizada
a função \textit{createReadStream} presente no módulo \textit{fs} (nativo da plataforma do \textit{Node.JS}) para
criar um \textit{stream} de leitura. Este trecho de código deve ser inserido dentro do servidor previamente 
implementado no Código~\ref{cod:base}.

O código apresenta uma sequência de operações que visam processar dados de um arquivo \textit{CSV} e 
transformá-los em formato \textit{JSON} (\textit{JavaScript object notation}). Através de uma abordagem baseada 
em fluxos de dados, o código executa alguma etapas de processamento. Após a criação da \textit{stream}, 
os dados do arquivo são canalizados em um processo de 
transformação usando o método \textit{pipeThrough} duas vezes. A primeira envolve a 
conversão dos dados \textit{CSV} em \textit{JSON}, através de uma biblioteca da comunidade (\textit{csvtojson}), 
selecionando apenas três propriedades escolhidas arbitrariamente. A conversão foi realizada a fim de facilitar
a manipulação dos dados no formato nativo da linguagem \textit{JavaScript}. O segundo processamento cria uma 
transformação personalizada, onde os dados \textit{JSON} são processados um a um. 
Para cada \textit{chunk} do arquivo, os campos são extraídos e usados para criar um novo objeto 
\textit{JSON} com os campos renomeados. Este processamento foi realizado apenas para demonstrar que, além de uma simples
transferência de dados, é possível realizar processos intermediários dentro do fluxo criado.

Para finalizar o processamento, a saída da transformação é canalizada para uma saída de uma resposta à requisição
\textit{HTTP}, realizada através do método \textit{pipeTo}. A opção \textit{signal} cria a possibilidade de 
cancelar a operação, o que é especialmente útil em cenários em que a mesma precisa ser interrompida. Todos os utilitários
usados para leitura (\textit{Readable}), escrita (\textit{Writable}) e transformação (\textit{Transform}) são ofertados
pelo módulo nativo \textit{stream} da plataforma do \textit{Node.JS}.

\begin{lstlisting}[caption={Implementação da leitura do arquivo de forma assíncrona}, label=cod:async]
	await Readable.toWeb(createReadStream(filename))
		.pipeThrough(
			Transform.toWeb(
				csvtojson({ headers: ["cord_uid", "sha", "publish_time"] })
			)
		)
		.pipeThrough(
			new TransformStream({
				async transform(chunk, controller) {
					const {
						cord_uid: cordUid,
						sha,
						publish_time: publishTime,
					} = JSON.parse(Buffer.from(chunk));

					const mappedData = {
						cordUid,
						sha,
						publishTime,
					};

					controller.enqueue(JSON.stringify(mappedData).concat("\n"));
				},
			})
		)
		.pipeTo(Writable.toWeb(response), { signal: abortController.signal });
\end{lstlisting}

O Código~\ref{cod:async-cluster}, ainda, foi utilizado para a terceira versão do servidor, somando à técninca de leitura
assíncrona de arquivos com a clusterização, implementada a partir de módulo \textit{cluster}, nativo da plataforma
\textit{Node.JS}. É possível observar que o processo principal será responsável pela criação de processos filhos a partir
do comando \textit{fork}, criando uma quantidade de processos referente ao número de núcleos de processamento presentes
no processador da máquina. Os processos filhos, por sua vez, serão responsáveis pela instanciação de um servidor com 
a implementação de leitura assíncrona, igualmente como apresentada no Código~\ref{cod:async}.

\begin{lstlisting}[caption={Implementação da técnica de clusterização}, label=cod:async-cluster]
	if (cluster.isPrimary) {
		const numCPUs = os.cpus().length;

		for (let i = 0; i < numCPUs; i += 1) {
			cluster.fork();
		}

		console.log(`Number of workers: ${Object.keys(cluster.workers).length}`);

		cluster.on("exit", (worker) => {
			console.log(`Worker ${worker.process.pid} died`);
			cluster.fork();
		});
	} else {
		{ ... }
	}
\end{lstlisting}


\subsection{Base de teste}

A base de dados utilizada para testes foi escolhida baseando-se em seu tamanho (ordem de \textit{gigabytes}) com
o objetivo de garantir resultados significativos para o estudo. Escolheu-se uma base com dados estruturados com o 
objetivo de exemplificar a aplicação prática do processamento intermediário no processo de transferência. 
Ao optar por essa abordagem, busca-se enfatizar a necessidade de ir além da mera transferência direta, 
incorporando etapas de processamento que permitam aprimorar a integridade e utilidade dos dados no contexto de destino.

O arquivo final utilizado apresenta um tamanho de 1.65 GB, sendo do formato \textit{CSV} (\textit{comma separated values}) 
com 19 propriedades separadas em colunas. A extração foi realizada da base 
\textit{CORD-19: COVID-19 Open Research Dataset} \cite{BASE}. Destaca-se que a escolha foi realizada a partir 
de fontes confiáveis e respeitando os critérios éticos e legais. O tratamento das informações contidas será de 
acordo com as técnicas e métodos descritos nas seções subsequentes deste trabalho.


\subsection{Construção do ambiente de teste}

Será configurado um ambiente de teste composto por uma aplicação servidor, com o intuito de registrar e avaliar as métricas como consumo
de memória \textit{RAM} e \textit{CPU}, \textit{thoughput} (vazão de requisições 
por unidade de tempo) e latência do \textit{event loop} da aplicação nos três cenários propostos. 
O servidor de aplicação será baseado em \textit{Node.JS}, utilizando a versão 20.3.0. 

Para uma parte do monitoramento das aplicações será utilizado o \textit{software} \textit{Apache JMeter}, na
versão 5.6.2 \cite{JMETER}. Por meio de sua interface gráfica, esta ferramenta permite a criação de casos de teste,
com configurações de quantidade de clientes, repetições de uma mesma requisição e a adição de variáveis a serem 
observadas em cada requisição completada. A métrica a ser capturada utilizando esta ferramenta será a vazão (\textit{thoughput}),
que se refere à quantidade de requisições feitas à aplicação por unidade de tempo.

A ferramenta \textit{PM2} na versão 5.3.0 \cite{PM2}, oferece um \textit{dashboard} de monitoramento em tempo real da aplicação,
permitindo a captura do uso de memória \textit{RAM}, uso de \textit{CPU} e latência do \textit{event loop} do \textit{Node.js}, 
que se refere ao intervalo entre o registro de uma \textit{callback} e a execução da mesma.
No âmbito deste trabalho, o PM2 será empregado como uma ferramenta integral para a execução e 
monitoramento dos servidores. Com suas características abrangentes de gerenciamento de processos, o 
PM2 oferece a capacidade de iniciar, parar e reiniciar aplicativos de forma eficiente, facilitando a 
gestão contínua dos serviços. Além disso, sua habilidade em monitorar a saúde dos processos em execução, 
proporcionando informações detalhadas sobre a utilização de recursos como CPU e memória, permitirá uma 
visão abrangente do desempenho dos servidores.


% Descrever como vai ser a coleta de dados, monitoramento via software com interface gráfica
% ou biblioteca e outputs via command line


% MEMÓRIA
% THROUGHPUT VAZAO -  quantidade de requisições por tempo, sendo o tempo desde o começo da primeira amostra até o final da última amostra,
% LATÊNCIA DO EVENT LOOP (PM2) - se refere ao atraso entre a solicitação de uma operação assíncrona e a conclusão efetiva dessa operação
% CPU 


\subsection{Definição dos cenários de teste}

Serão definidos dois cenários de teste para avaliar o desempenho das implementações quando confrontadas
com uma transferência de um volume de dados de 1.65 \textit{gigabytes}. Os cenários de teste serão 
nomeados da seguinte forma:

\begin{enumerate}[a)]
\item Cenário 1: Implementação com arquitetura não específica para transferências da ordem de \textit{gigabytes}, 
ou seja, realização da leitura de arquivos de forma síncrona (Código~\ref{cod:sync}).
\item Cenário 2: Implementação com arquitetura escalável para transferências da ordem de \textit{gigabytes}, 
utilizando métodos da arquitetura baseada em eventos para ler arquivos de forma assíncrona (Código~\ref{cod:async}).
\item Cenário 3: Implementação com arquitetura escalável para transferências da ordem de \textit{gigabytes}, 
utilizando métodos da arquitetura baseada em eventos para ler arquivos de forma assíncrona somada à utilização de
\textit{cluster} (Código~\ref{cod:async-cluster}).
\end{enumerate}

\subsection{Coleta e análise de dados}

Os indicadores de desempenho a serem coletados e analisados para cada uma das implementações, durante a transferência
dos dados contidos na base previamente citada serão: Uso de memória \textit{RAM}, uso de \textit{CPU}, \textit{throughput}
e latência do \textit{event loop}.

No \textit{software} \textit{Apache JMeter}, serão desenvolvidos 3 cenários de teste correspondentes às 3 diferentes implementações.
Para avaliar o \textit{throughput} de cada caso de teste, serão usados X clientes, os quais enviarão solicitações à aplicação
de destino. As requisições dos clientes não serão feitas ao mesmo tempo, mas sim de forma escalonada, com cada
cliente disparando uma nova requisição a cada segundo. Isso resultará em um total de X requisições ao longo do teste.
Os valores de \textit{throughput} para cada cenário serão capturados ao fim da bateria de testes e agrupados para comparação.

Já as métricas capturadas pela plataforma \textit{PM2} são registradas em tempo real em forma de gráficos, que possibilitam uma 
análise, nesse caso, do uso de memória \textit{RAM}, uso de \textit{CPU} e latência do \textit{event loop}, durante o tempo em
que ocorre a requisição e transferência de dados.


\section{Resultados e discussão} 

\begin{table}[!h]
\centering
\caption{Throughput para os 3 cenários propostos}
\label{tab:exemplo}
\begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|}
\hline
\textbf{Coluna 1} & \textbf{Coluna 2} & \textbf{Coluna 3} \\
\hline
Valor 1 & Valor 2 & Valor 3\\
\hline
\end{tabular}
\end{table}


\section{Considerações finais}



\bibliographystyle{sbc}
\bibliography{referencias}

\end{document}